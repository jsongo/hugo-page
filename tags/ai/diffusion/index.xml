<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI/Diffusion on Ethan 的思考札记</title><link>https://www.jsongo.top/tags/ai/diffusion/</link><description>Recent content in AI/Diffusion on Ethan 的思考札记</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://www.jsongo.top/tags/ai/diffusion/index.xml" rel="self" type="application/rss+xml"/><item><title>初识 Diffusion（概念）</title><link>https://www.jsongo.top/articles/diffusion-101/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jsongo.top/articles/diffusion-101/</guid><description>&lt;img src="https://cdn.jsongo.top/banners/96539755245eb88510f037ed2d24f60d.jpeg" alt="Featured image of post 初识 Diffusion（概念）" />&lt;p>Diffusion（扩散模型）是一类生成式模型，在机器学习和人工智能领域应用广泛，特别是在图像生成、语音合成等领域发挥了重要作用。&lt;/p>
&lt;h1 id="clip">CLIP
&lt;/h1>&lt;h2 id="概念">概念
&lt;/h2>&lt;ul>
&lt;li>&lt;strong>CLIP 模型&lt;/strong>：CLIP 是 Contrastive Language-Image Pre-training 的缩写，由 OpenAI 在 2021 年 1 月 5 日发布，是一种将计算机视觉与自然语言处理相结合的神经网络模型。
&lt;ul>
&lt;li>它通过对 400,000,000 组（图像，文本）对数据进行预训练，从而能够在给定图像的情况下，根据自然语言指令预测出最相关的文本片段，展现出了类似 GPT-2 和 GPT-3 的 zero-shot 学习能力，即模型可以在未针对特定任务进行直接优化训练的情况下，对未曾见过的数据类别进行较好地预测&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>CLIP Vision&lt;/strong>：CLIP Vision 主要负责处理视觉信息，也就是对输入的图像数据进行特征提取和编码等操作，将图像转化为模型能够理解和处理的向量表示，以便与文本信息进行对比学习和关联。
&lt;ul>
&lt;li>例如，在图像生成领域，CLIP Vision 可以帮助模型理解图像的内容和特征，从而生成更符合语义描述的图像。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>CLIP Text&lt;/strong>：我们常看到的这个 CLIP Text 概念，主要是指作为参考文本来对图像进行调整的文本描述。&lt;/li>
&lt;/ul>
&lt;h2 id="应用">应用
&lt;/h2>&lt;ul>
&lt;li>&lt;strong>图像生成&lt;/strong>：如在 Paints-Undo 项目中，CLIP Vision 作为模型架构的一部分，与其他组件共同作用，通过对输入图像的处理和分析，为生成模拟人类绘画过程的动画提供视觉信息基础，帮助模型理解图像的内容和结构，从而更准确地生成绘画过程中的各个中间帧.&lt;/li>
&lt;li>&lt;strong>图像分类与标注&lt;/strong>：可以根据图像的视觉特征，结合预训练时学习到的图像与文本的关联，对未见过的图像进行分类或自动生成相应的文本标注，比如判断一张图片是风景照、人物照还是动物照，并给出相应的文字描述。&lt;/li>
&lt;li>&lt;strong>图像检索&lt;/strong>：基于 CLIP Vision 对图像特征的提取和与文本的关联能力，可以实现根据文本描述来检索相关的图像，或者根据图像来查找与之语义相关的文本信息，提高图像检索的准确性和效率。&lt;/li>
&lt;li>&lt;strong>视觉问答系统&lt;/strong>：帮助系统理解图像中的视觉内容，结合对自然语言问题的理解，生成准确的文本答案，例如回答关于图像中物体的位置、颜色、数量等问题 。&lt;/li>
&lt;/ul>
&lt;h1 id="vae">VAE
&lt;/h1>&lt;p>VAE 主要用于将图像数据压缩到一个潜在空间，然后再从这个潜在空间中生成新的图像，侧重于图像的生成和重建。&lt;/p>
&lt;h2 id="latent-image">Latent Image
&lt;/h2>&lt;p>经过某种变换或编码后隐藏在数据中的图像信息。例如，在使用变分自编码器（VAE）进行图像生成或处理时，图像数据会被压缩到一个潜在空间（latent space），这个潜在空间中的向量可以被看作是潜像的一种表示形式。这些潜像向量包含了图像的关键特征，如形状、颜色、纹理等信息，通过解码器可以将这些潜像向量转换回可见的图像。&lt;/p>
&lt;h1 id="lora">Lora
&lt;/h1>&lt;p>LoRA 是一种用于微调预训练模型的技术，通过在原始模型的基础上添加少量可训练的参数来实现对模型的微调。&lt;/p></description></item></channel></rss>