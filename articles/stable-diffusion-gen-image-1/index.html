<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Stable Diffusion 是一种先进的生成式人工智能技术，是目前比较流行的一种用于生成高质量的图像的技术之一。它在模型架构中采用了 Transformer 架构的一些特性，基于扩散模型架构来生成图片"><title>Stable Diffusion 生图技术（一）</title>
<link rel=canonical href=https://www.jsongo.top/articles/stable-diffusion-gen-image-1/><link rel=stylesheet href=/scss/style.min.864cf8b246e193359d04f90b7d58a230abe27013f6afd42a6834e34e5f8a880f.css><script src=https://res.wx.qq.com/open/js/jweixin-1.6.0.js></script><script>wx.ready(function(){wx.updateAppMessageShareData({title:"Stable Diffusion 生图技术（一）",desc:"Stable Diffusion 是一种先进的生成式人工智能技术，是目前比较流行的一种用于生成高质量的图像的技术之一。它在模型架构中采用了 Transformer 架构的一些特性，基于扩散模型架构来生成图片",link:"https://www.jsongo.top/articles/stable-diffusion-gen-image-1/",imgUrl:"https://cdn.jsongo.top/banners/772c64fbb07e3cd46573602f922a7829.jpg",success:function(){}})})</script><meta property='og:title' content="Stable Diffusion 生图技术（一）"><meta property='og:description' content="Stable Diffusion 是一种先进的生成式人工智能技术，是目前比较流行的一种用于生成高质量的图像的技术之一。它在模型架构中采用了 Transformer 架构的一些特性，基于扩散模型架构来生成图片"><meta property='og:url' content='https://www.jsongo.top/articles/stable-diffusion-gen-image-1/'><meta property='og:site_name' content='Ethan 的思考札记'><meta property='og:type' content='article'><meta property='article:section' content='Articles'><meta property='article:tag' content='AI/工具'><meta property='article:published_time' content='2024-11-19T16:36:27+08:00'><meta property='article:modified_time' content='2024-11-19T16:36:27+08:00'><meta property='og:image' content='https://cdn.jsongo.top/banners/772c64fbb07e3cd46573602f922a7829.jpg'><meta name=twitter:title content="Stable Diffusion 生图技术（一）"><meta name=twitter:description content="Stable Diffusion 是一种先进的生成式人工智能技术，是目前比较流行的一种用于生成高质量的图像的技术之一。它在模型架构中采用了 Transformer 架构的一些特性，基于扩散模型架构来生成图片"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://cdn.jsongo.top/banners/772c64fbb07e3cd46573602f922a7829.jpg'><link rel="shortcut icon" href=https://cdn.jsongo.top/mc/favicon.jpg></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu7049013329120086875.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Ethan 的思考札记</a></h1><h2 class=site-description>Keeping Grit!</h2></div></header><ol class=menu-social><li><a href=https://github.com/jsongo target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/page/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/page/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/page/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li><a href=/about target=_blank><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About Me</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ul><li><a href=#概述>概述</a><ul><li><a href=#背景>背景</a></li><li><a href=#技术简介>技术简介</a></li></ul></li><li><a href=#生图过程>生图过程</a><ul><li><a href=#模型-checkpoint跟采样的关系>模型 （Checkpoint）跟采样的关系</a></li><li><a href=#clip-text-encode>CLIP Text Encode</a></li><li><a href=#采样>采样</a></li><li><a href=#vae-decoder变分自解码器>VAE Decoder（变分自解码器）</a></li><li><a href=#latent-image>Latent Image</a></li></ul></li><li><a href=#stability-ai-官方>Stability AI 官方</a><ul><li><a href=#体验>体验</a></li></ul></li><li><a href=#字节的-lighting-模型>字节的 Lighting 模型</a><ul><li><a href=#小科普可跳过>小科普（可跳过）</a><ul><li><a href=#概念>概念</a></li><li><a href=#从参数规模与训练成本来看>从参数规模与训练成本来看</a></li></ul></li><li><a href=#使用>使用</a></li></ul></li></ul></nav></div></section><section class="widget tagCloud"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg></div><h2 class="widget-title section-title">Tags</h2><div class=tagCloud-tags><a href=/tags/ai/diffusion/ class=font_size_3>AI/Diffusion
</a><a href=/tags/area/thinking/ class=font_size_2>Area/Thinking
</a><a href=/tags/it/%E6%8A%98%E8%85%BE/azure/ class=font_size_2>IT/折腾/Azure
</a><a href=/tags/%E8%BE%93%E5%85%A5/%E4%B9%A6/ class=font_size_2>输入/书
</a><a href=/tags/ai/%E5%8E%9F%E7%90%86/ class=font_size_1>AI/原理
</a><a href=/tags/ai/%E5%B7%A5%E5%85%B7/ class=font_size_1>AI/工具
</a><a href=/tags/area/life/2024/ class=font_size_1>Area/Life/2024
</a><a href=/tags/area/life/weekly/ class=font_size_1>Area/Life/Weekly
</a><a href=/tags/area/%E6%80%9D%E8%80%83/ class=font_size_1>Area/思考
</a><a href=/tags/clippings/ class=font_size_1>Clippings</a></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/articles/stable-diffusion-gen-image-1/><img src=https://cdn.jsongo.top/banners/772c64fbb07e3cd46573602f922a7829.jpg loading=lazy alt="Featured image of post Stable Diffusion 生图技术（一）"></a></div><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/articles/stable-diffusion-gen-image-1/>Stable Diffusion 生图技术（一）</a></h2><h3 class=article-subtitle>Stable Diffusion 是一种先进的生成式人工智能技术，是目前比较流行的一种用于生成高质量的图像的技术之一。它在模型架构中采用了 Transformer 架构的一些特性，基于扩散模型架构来生成图片</h3></div><footer class=article-tags><div><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<a href=/tags/AI/%e5%b7%a5%e5%85%b7>AI/工具</a></div></footer><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Tue, Nov 19, 2024</time></div></footer></div></header><section class=article-content><h1 id=概述>概述</h1><h2 id=背景>背景</h2><p>Stable Diffusion 最初是由德国慕尼黑大学的 CompVis 研究小组、纽约的 RunwayML 公司等组成的国际研究团队开发的，后来 Stability AI 参与其中并推动了其发展。<br>Stable Diffusion 的发展历程如下：<br><img src=https://cdn.jsongo.top/2024/12/afb65322de6b531c0c01e86e6d27c0e0.webp loading=lazy alt=|900></p><h2 id=技术简介>技术简介</h2><p>Stable Diffusion 在模型架构中采用了 Transformer 架构的一些特性，基于扩散模型架构来生成图片。<br>它的原理用白话说，比较简单：加噪和去噪（专业术语叫前向扩散和反向扩散）。加噪后的图片主要用于训练或作为初始输入（latent），然后训练一个模型去实现某些图像生成目标（去噪过程）。</p><ul><li><strong>前向扩散</strong>：在前向阶段，通过向原始图像数据（如真实的照片或绘画）添加噪声，逐步将图像转换为纯噪声。这个过程是在多个时间步（time - steps）中完成的，每一步都按照一定的规则（通常是基于高斯分布）添加噪声，使得图像信息逐渐被噪声掩盖。例如，开始时图像可能还比较清晰，随着时间步的增加，图像越来越模糊，最终变成完全的噪声。</li><li><strong>反向扩散</strong>：这是生成图像的关键阶段。从纯噪声开始，模型通过学习到的去噪过程，逐步恢复图像信息。模型会预测每个时间步中需要去除的噪声，经过多个时间步的迭代，最终生成一张类似于训练数据分布的图像。这个过程类似于从无序的噪声中逐渐 “雕刻” 出有意义的图像。</li></ul><h1 id=生图过程>生图过程</h1><p><img src=https://cdn.jsongo.top/2024/11/d66a5473be54d712b3aa8e879f9a8c3a.webp loading=lazy alt=|700></p><h2 id=模型-checkpoint跟采样的关系>模型 （Checkpoint）跟采样的关系</h2><p>Checkpoint 包含了模型在特定训练阶段的所有权重、偏置以及优化器的状态等信息，而采样模型的参数是由 Checkpoint 所确定的，采样模型使用该 Checkpoint 中存储的权重和其他参数进行计算。不同的 Checkpoint 会导致采样模型在生成图像时表现出不同的性能和风格。例如，某些 Checkpoint 可能侧重于生成高分辨率的图像，而另一些可能更擅长生成具有特定艺术风格的图像。这是因为在训练过程中，不同的 Checkpoint 所对应的训练数据和训练目标可能有所不同，从而影响了采样模型的行为。</p><h2 id=clip-text-encode>CLIP Text Encode</h2><p>属于 Condition 节点，它用 CLIP 模型对文本 Prompt 进行编码，对模型生成的结果进行方向上的引导，其实可能理解为文本模型中的 embedding。</p><h2 id=采样>采样</h2><p>生图其实就是一个反向扩散的过程，从一个完全是噪声的图像开始，通过模型逐步去除噪声来生成图像。这个过程通过一个采样函数来实现，它基于模型预测的噪声来更新噪声图像。<br><img src=https://cdn.jsongo.top/2024/12/dd2433499e7a9229aa5bd816177c8988.webp loading=lazy></p><ul><li><strong>Steps</strong>，迭代生图，每次更新噪声图像，需要经过多个 Step 的迭代。随着 Step 反复执行，图像中的噪声逐渐减少，最终生成一个近似原始图像分布的图像。不过生成的图像质量可能会受到多种因素的影响，如模型的性能、采样方法、时间步数等。在实际应用中，可能需要对生成的图像进行后处理（如调整颜色、对比度等）来提高图像质量。</li><li><strong>seed</strong>，种子值，用于初始化随机数生成器。相同的种子值在相同的模型和参数设置下会生成相同的图像，这有助于复现结果。</li><li><strong>control_after_generate</strong>：这个参数可能与生成后的控制操作有关，例如对生成的图像进行随机化处理</li><li><strong>steps</strong>：指生成过程中的迭代步数。步数越多，生成的图像通常会越精细，但也会增加计算时间。</li><li><strong>cfg</strong>（Classifier-Free Guidance）：无分类器引导的强度，它是一种在生成式模型（如 Stable Diffusion）中用于引导图像生成方向的技术，决定了模型在生成图像时对正向提示（你希望在图像中出现的内容）的遵循程度。较高的 CFG 值会使生成的图像更紧密地遵循正向 Prompt，但也有可能导致图像过度拟合。<ul><li>取值范围：<ul><li>CFG 的值通常在 1 到 20 之间，理论上可以取更高的值，但在实际应用中，过高的值往往会导致图像质量下降。</li></ul></li><li>较低值（1 - 4）：<ul><li>当 CFG 值较低时，生成的图像会更具随机性和创造性。模型对正向提示的遵循程度较弱，因此可能会生成一些与提示不太相关但具有独特创意的图像。这种情况下，图像可能会包含一些意外的元素或风格。</li></ul></li><li>中等值（4 - 10）：<ul><li>在这个范围内，是比较常用的取值。模型会在遵循正向提示和保持一定的创造性之间取得较好的平衡。能够生成与提示较为符合的图像，同时也不会显得过于刻板。</li></ul></li><li>较高值（10 - 20）：<ul><li>当 CFG 值较高时，生成的图像会非常紧密地遵循正向提示。这可能会导致图像过于 “完美” 地符合提示，但也可能会出现一些问题，比如图像的细节可能会显得不自然，色彩可能会过于饱和，或者图像可能会失去一些自然的随机性和美感</li></ul></li></ul></li><li><strong>sampler_name</strong>：这是指采样器的名称。不同的采样器（如 Euler、Langevin 等）有不同的特性，会影响图像生成的速度和质量。</li><li><strong>scheduler</strong>：调度器，用于控制生成过程中的步长和其他参数。不同的调度器会影响生成的效率和结果。</li><li><strong>denoise</strong>：去噪参数控制生成过程中对噪声的去除程度。较低的去噪值会使生成的图像更具随机性，而较高的值会使图像更平滑和可预测。</li></ul><h2 id=vae-decoder变分自解码器>VAE Decoder（变分自解码器）</h2><p>图像数据往往是高维的，包含大量的像素信息，所以一般训练和计算时，往往要压缩到低维来处理，用更紧凑的方式表示图像的关键特征，就像文本模型中的 Embedding 处理，变成稠密的数据，在图像处理领域叫潜在空间（Latent Space）。而解码器则是将潜在空间中的表示再转换回图像数据空间，尽可能地重建原始图像。<br>生成新图的过程，由于潜在空间是连续的，稍微改变潜在空间中的向量值，就可以生成与原始图像在某些特征上有所变化的新图像。例如，在生成人脸图像的 VAE 模型中，在潜在空间中沿着某个方向移动向量可能会改变人脸的表情、发型或者年龄等特征。</p><h2 id=latent-image>Latent Image</h2><p>一般在整个 ComfyUI 流程中，会插入一张空的（Empty） Lantent Image，它提供了一个初始的 “画布”，让模型在这个基础上进行生成或转换操作。<br>当然如果是对已有的图片进行调整、修复或优化，则可以把空的图换成一张现成的图片，这时就要把它加载并转换为合适的潜在表示形式后，可以作为生成过程的起点。在 ComfyUI 中，可能涉及到将图片通过适当的预处理步骤，如调整大小、归一化等操作后，然后将其编码为潜在空间中的表示，这样就可以基于已有的图像内容进行修改、风格转换或者其他生成操作。</p><h1 id=stability-ai-官方>Stability AI 官方</h1><p>Stable Diffusion 的官方可用的模型，可以从 API 文档中看到： <a class=link href=https://platform.stability.ai/pricing target=_blank rel=noopener>Stability AI - Developer Platform</a>。最新的是 SD 3.5（2024 年 11 月）。</p><ul><li>1 credit = $0.01</li><li>这么算，生成一张 SD 3.5 的图片，medium 要 $0.035，差不多 0.25 元，4 张 1 块。<br><img src=https://cdn.jsongo.top/2024/11/207f1abc8b1be591d3f76ec236344c3c.webp loading=lazy alt=736deaffc1c02497df089d14539fba5d_MD5|700></li></ul><h2 id=体验>体验</h2><p><a class=link href=https://stabledifffusion.com/tools/ai-image-generator target=_blank rel=noopener>Free AI Image Generator - Turn Text to Image Online | Stable Diffusion Online</a></p><h1 id=字节的-lighting-模型>字节的 Lighting 模型</h1><p><a class=link href=https://huggingface.co/ByteDance/SDXL-Lightning target=_blank rel=noopener>ByteDance/SDXL-Lightning at main</a> 字节的这个模型生成效果相当不错。<br>它同时提供了 Full UNet 和 LoRA 版本，都是相对比较小的蒸馏模型（虽然 UNet 也有几个 G）。</p><blockquote><p>We provide both full UNet and LoRA checkpoints. The full UNet models have the best quality while the LoRA models can be applied to other base models.</p></blockquote><h2 id=小科普可跳过>小科普（可跳过）</h2><h3 id=概念>概念</h3><ul><li>UNet 是卷积神经网络（CNN）的一种特殊架构，在生成对抗网络 (GANs) 和扩散模型中广泛使用。它是一种完整的网络架构，专门用于图像分割任务，从输入图像到输出分割结果，有自己独立的结构和训练流程。</li><li>LoRA 不是一种独立的网络架构，而是一种模型微调策略，可以应用于各种现有的预训练模型（包括但不限于基于 UNet 架构的模型），用于在不大量修改原始模型结构的情况下进行任务适配。</li></ul><h3 id=从参数规模与训练成本来看>从参数规模与训练成本来看</h3><ul><li><strong>UNet</strong>：在训练过程中，需要对整个网络的参数进行学习和更新，尤其是在处理高分辨率图像或复杂任务时，可能需要大量的训练数据和计算资源。</li><li><strong>LoRA</strong>：通过低秩分解减少了需要训练的参数数量，在对大型预训练模型进行微调时，训练成本显著降低，对数据量的要求也相对较少。<br>UNet 的模型一般都比较大：<br><img src=https://cdn.jsongo.top/2024/11/8f1f152a35835044e0ea8fc381a9333b.webp loading=lazy alt=|475><br>LoRA 则小很多<br><img src=https://cdn.jsongo.top/2024/11/36b48790266f80b2cb03cfc22ded0f13.webp loading=lazy alt=|475></li></ul><h2 id=使用>使用</h2><p>它们都有 2-Step, 4-Step, 8-Step，其中 1-step 只是实验性的、效果不好、质量不稳定，一般建议用折中的 4-step，如果资源充足可以选质量最好的 8-step。<br>ComfyUI 中的使用非常简单：<br><img src=https://cdn.jsongo.top/2024/11/fc799454d0483ec8b7fea253e7ce45e4.webp loading=lazy alt=|675><br>如果只是想玩玩，可以直接在 huggingface 上试试：<a class=link href=https://huggingface.co/spaces/ByteDance/SDXL-Lightning target=_blank rel=noopener>SDXL-Lightning spaces</a> ，效果还是不错的：<br><img src=https://cdn.jsongo.top/2024/11/22638b08323398c180c2d2ff0d1e59f8.webp loading=lazy alt=|700></p></section><footer class=article-footer><section class=article-tags><a href=/tags/ai/%E5%B7%A5%E5%85%B7/>AI/工具</a></section></footer></article><script src=https://giscus.app/client.js data-repo=jsongo/hugo-page data-repo-id=R_kgDONQf4yA data-category=Announcements data-category-id=DIC_kwDONQf4yM4CkfAr data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"preferred_color_scheme":"dark_dimmed")}})()</script><footer class=site-footer><section class=copyright>&copy;
2024 Ethan 的思考札记</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.29.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>